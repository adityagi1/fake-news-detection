help()
q()
install.packages("tidyverse")
install.packages("nycflights2013")
install.packages("nycflights13")
library(tidyverse)
library(nycflights13)
flights
jan1 = filter(flights, month == 1, day == 1 )
jan1
head(arrange(flights, year, month, day))
flights %>% select(year, month, day) %>%head()
flights %>% select(-year)
?starts_with
flights %>% select(starts_with("dep"))
flights %>% select(starts_with("dep")) %>% head()
select(flights, time_hour, air_time, everything())
flights_sml = flights %>% select(year:day, ends_with("delay"), distance, air_time)
flights_sml
flights_sml %>% mutate(gain = arr_delay - dep_delay, speed = distance/ air_time * 60) %>% head()
summarise(flights, delay = mean(dep_delay, na.rm = TRUE))
summarise(flights, mean(dep_delay, na.rm = TRUE))
flights %>% group_by(day, month, year) %>% summarise(delay = mean(dep_delay, na.rm = TRUE))
flights %>% group_by(year, month, day) %>% summarise(delay = mean(dep_delay, na.rm = TRUE))
flights %>% group_by(year, month, day) %>% summarise(delay = mean(dep_delay, na.rm = TRUE)) %>% head()
flights %>% group_by(year, month, day) %>% summarise(delay = mean(dep_delay)) %>% head()
View(flights_sml)
View(flights_sml)
flights
flights %>% filter(carrier = "UA" | carrier = "AA" | carrier == "DL")
flights %>% filter(carrier == "UA" | carrier == "AA" | carrier == "DL")
flights %>% filter(carrier == "UA" || carrier == "AA" || carrier == "DL")
flights %>% filter(carrier == "UA" | carrier == "AA" | carrier == "DL")
flights %>% arrange(desc(air_time)) %>% select(air_time. everything())
flights %>% arrange(desc(air_time)) %>% select(air_time, everything())
select(flights, distance, distance)
select(flights, distance, air_time)
summarise(flights, max_delay = max(dep_delay, na.rm = TRUE))
fliter(flights, dep_delay = max(dep_delay, na.rm = TRUE))
filter(flights, dep_delay = max(dep_delay, na.rm = TRUE))
filter(flights, dep_delay == max(dep_delay, na.rm = TRUE))
flights_sml = flights %>% filter(month = 1 & carrier %in% c("UA", "AA", "DL"))
flights_sml = flights %>% filter(month == 1 & carrier %in% c("UA", "AA", "DL"))
flights
ggplot(data = flights_sml, mapping = aes(x = dep_delay, y = arr_delay, geom_point()))
ggplot(flights_sml, aes(x = dep_delay, y = arr_delay, geom_point()))
ggplot(flights_sml, aes(x = dep_delay, y = arr_delay +  geom_point()))
ggplot(flights_sml, aes(x = dep_delay, y = arr_delay)) + geom_point()
ggplot(flights_sml, aes(x = dep_delay, y = arr_delay))
ggplot(flights_sml, aes(x = dep_delay, y = arr_delay)) + geom_point(color = "yellow")
ggplot(flights_sml, aes(x = dep_delay, y = arr_delay, color = "blue")) + geom_point()
ggplot(flights_sml, aes(x = dep_delay, y = arr_delay, color = carrier)) + geom_point()
ggplot(flights_sml, aes(x = dep_delay, y = arr_delay, size = carrier)) + geom_point()
ggplot(flights_sml, aes(x = dep_delay, y = arr_delay, shape = carrier)) + geom_point()
ggplot(flights_sml, aes(x = dep_delay, y = arr_delay)) + geom_point(color = "purple")
flights_sml %>% ggplot(aes(x = dep_delay, y = arr_delay)) + geom_point() + facet_wrap(~ carrier, nrow = 1)
ggplot(flights_sml, aes(x = dep_delay, y = arr_delay)) + geom_curve()
ggplot(flights_sml, aes(x = dep_delay, y = arr_delay)) + geom_smooth()
ggplot(flights_sml, aes(x = distance, y = air_time)) + geom_smooth()
ggplot(flights_sml, aes(x = distance, y = air_time)) + geom_point()
ggplot(flights_sml, aes(x = distance, y = air_time)) + geom_smooth()
flights_sml %>% ggplot(aes(x = carrier)) + geom_bar()
exit
quit
library(tidyverse)
?tidyverse
library(nycflights13)
table1
?table1
table2
table4a
table4b
table4a
?gather
table4a %>% gather('1999', '2000', key = "year", value = "cases")
table4a %>% gather('1999', '2000', key = "cases", value = "year")
table4a %>% gather('1999', '2000')
table4a %>% gather('1999'
)
table4a
gather('1999', '2000', key = "year", value = "cases")
gather("1999", "2000", key = "year", value = "cases")
table4a %>% gather("1999", "2000", key = "year", value = "cases")
table2
table2 %>% head()
table1
table4a
table4a %>% gather("1999", "2000", key = "year", value = "cases")
table2 %>% spread(key = "year", values = "cases")
table2 %>% spread(key = "year", value = "cases")
table2 %>% spread(key = "type", value = "count")
?spread
table2
planes %>% count(tailnum)
planes %>% count(tailnum) %>% filter(n>1)
flights2 %>% flights %>% select(year: day, hour, origin, dest, tailnum, carrier)
flights2 = flights %>% select(year: day, hour, origin, dest, tailnum, carrier)
head(flights2)
flights2 %>% select(-origin, -dest) %>% left_join(airlines, by = "carrier")
airports %>% head()
flights2
airports %>% filter(faa == JFK)
airports %>% filter(faa == "JFK")
flihgts2 %>% left_join(airports, by = c("dest"= "faa"))
flights2 %>% left_join(airports, by = c("dest"= "faa"))
rm(flights_sml)
rm(jan1)
install.packages("glmnet")
library(glmnet)
library(tidyverse)
library(stringr)
library(glmnet)
library(pls)
install.packages(pls)
install.packages("pls")
install.packages(stringr)
install.packages("stringr")
install.packages("stringr")
rm(list = ls())
library(tidyverse)
library(tidyverse)
mpg
ggplot(mpg) + geom_point(aes(x=displ, y = hwy))
ggplot(mpg) + geom_point(aes(x=displ, y = hwy, color = class))
ggplot(mpg) + geom_point(aes(x=displ, y = hwy))
ggplot(mpg) + geom_point(aes(x=displ, y = hwy, color = blue))
ggplot(mpg) + geom_point(aes(x=displ, y = hwy, color = "blue"))
ggplot(mpg) + geom_point(aes(x=displ, y = hwy), color = "blue")
ggplot(mpg) + geom_point(aes(x=displ, y = hwy))
ggplot(mpg) + geom_point(aes(x=displ, y = hwy), color = "blue")
ggplot(mpg) + geom_point(aes(x=displ, y = hwy, shape = class), color = "blue")
ggplot(mpg) + geom_point(aes(x=displ, y = hwy, alpha = class), color = "blue")
mpg$drv
unique(mpg$drv)
unique(mpg$cyl)
library(tidytext)
install.packages("tidytext")
library(tidytext)
library(janeaustenr)
library(tidyverse)
austen_books()
austen = austen_books()
View(austen)
text[5]
View(austen)
View(austen)
austen_books() %>% group_by(book)
grouped = austen %>% group_by(book)
View(grouped)
?str_detect
?cumsum()
orignal_books = austen_books() %>% group_by(book) %>% mutate(linenumber = row_number(), chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]", ignore_case  = TRUE)))) %>% ungroup()
?str_detect
library(stringr)
orignal_books = austen_books() %>% group_by(book) %>% mutate(linenumber = row_number(), chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]", ignore_case  = TRUE)))) %>% ungroup()
orignal_books
original_books = orignal_books
rm(orignal_books)
tidy_books = original_books %>% unnest_tokens(word, text)
tidy_books
?anti_join
tidy_books = tidy_books %>% anti_join(stop_words)
data("stop_words")
tidy_books = tidy_books %>% anti_join(stop_words)
tidy_books = tidy_books %>% anti_join(stop_words)
tidy_books
stop_words
tidy_books
count(tidy_books, word)
count(tidy_books, word, sort = TRUE)
library(tidyverse)
library(tidytext)
library(gutenbergr)
install.packages("gutenbergr")
library(gutenbergr)
hg_wells = gutenberg_download(c(35,36,5230,159))
hg_wells
View(hg_wells)
tidy_hgwells = hg_wells %>% unnest_tokens(word, text)
tidy_hgwells = tidy_hgwells %>% antijoin(stop_words)
library(dplyr)
tidy_hgwells = tidy_hgwells %>% antijoin(stop_words)
tidy_hgwells = tidy_hgwells %>% anti_join(stop_words)
stop_words
%>% hg_wells %>% unnest_tokens(word, text)
hg_wells %>% unnest_tokens(word, text)
tidy_hgwells
count(hg_wells, word)
count(tidy_hgwells, word)
count(tidy_hgwells, word, sort = TRUE)
bronte = gutenberg_download(c(1260, 768, 969, 9182, 767))
bronte
View(bronte)
tidy_bronte = bronte %>% unnest_tokens(word, text) %>% anti_join(stop_words)
count(tidy_bronte, word, sort = TRUE)
janeaustenr()
austen_books()
library(janeaustenr)
austen_books()
austen = austen_books()
mutate(tidy_bronte,author = "Bronte Sisters")
frequency = bind_rows(mutate(tidy_bronte, author = "Bronte Sisters"), mutate(tidy_hgwells, author = "HG Wells"))
frequency
unique(frequency$author)
unique(frequency$gutenberg_id)
frequency = frequency %>% str_extract(word = str_extract(word, "[a-z']+"))
library(stringr)
frequency = frequency %>% str_extract(word = str_extract(word, "[a-z']+"))
frequency = frequency %>% mutate(word = str_extract(word, "[a-z']+"))
frequency
frequency %>% count(author)
frequency %>% count(author, word)
frequency = frequency %>% count(author, word)
frequency
frequency %>% group_by(author)
a = frequency %>% group_by(author)
View(a)
View(frequency)
?group_by
rm(a)
frequency = frequency %>% group_by(author)
?dplyr
frequency %>% mutate(proportion = n/sum(n))
frequency = frequency %>% mutate(proportion = n/sum(n))
frequency
frequency = frequency %>% select(-n)
frequency
frequency %>% spread(author, proportion)
frequency = frequency %>% spread(author, proportion)
frequency %>% gather(author, proportion, "Bronte Sisters": "HG Wells")
frequency = frequency %>% gather(author, proportion, "Bronte Sisters": "HG Wells")
library(scales)
View(frequency)
ggplot(frequency, aes(x = proportion, y = "Jane Austen", color = abs("Jane Austen" - proportion))) +
geom_abline(color = "gray40", lty = 2) + geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word, check_overlap = TRUE, vjust = 1.5)) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0,0.001), low = "darkslategrey4", high = "gray75")
ggplot(frequency, aes(x = proportion, y = `Jane Austen`, color = abs(`Jane Austen` - proportion))) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
facet_wrap(~author, ncol = 2) +
theme(legend.position="none") +
labs(y = "Jane Austen", x = NULL)
library(tidyverse)
library(tidytext)
sentiments
get_sentiments('nrc')
get_sentiments('afinn')
get_sentiments('bing')
quit()
library(tidyverse)
library(tidytext)
lexicon
sentiments
get_sentiments("nrc")
get_sentiments("afinn")
get_sentiments("bing")
library(janeaustenr)
library(dplyr)
library(stirngr)
library(stringr)
austen_books()
tidy_books = austen_books() %>% group_by(book) %>% mutate(linenumber = row_number(), chapter = cumsum(str_detect(text, regex("^chapter[\\divxlc]", ignore_case = TRUE)))) %>% ungroup() %>% unnest_tokens(word, text)
get_sentiments('nrc')
get_sentiments('nrc') %>% filter(sentiment == "joy")
nrcjoy = get_sentiments('nrc') %>% filter(sentiment == "joy")
tidy_books
tidy_books = tidy_books %>% select(word, everything())
tidy_books
?inner_join
tidy_books %>% filter(book = "Emma") %>% inner_join(nrcjoy, by = "word")
tidy_books %>% filter(book = "Emma") %>% inner_join(nrcjoy, "word")
tidy_books %>% filter(book == "Emma") %>% inner_join(nrcjoy, by = "word")
tidy_books %>% filter(book == "Emma") %>% inner_join(nrcjoy, by = "word") %>% count(word, sort = TRUE)
?table
?count
get_sentiments("bing")
get_sentiments("adinn")
get_sentiments("afinn")
get_sentiments("bing")
tidy_books()
tidy_books
tidy_books %>% inner_join(get_sentimens("bing"), by = "word")
tidy_books %>% inner_join(get_sentiments("bing"), by = "word")
tidy_books %>% inner_join(get_sentiments("bing"), by = "word") %>% count(book, index = linenumber %/% 80, sentiment)
tidy_books %>% inner_join(get_sentiments("bing"), by = "word") %>% count(book, index = linenumber %/% 80, sentiment) %>% spread(sentiment, n, fill = 0)
tidy_books %>% inner_join(get_sentiments("bing"), by = "word") %>% count(book, index = linenumber %/% 80, sentiment) %>% spread(sentiment, n, fill = 0) %>% mutate(sentiment = positive - negative)
janeaustensentiment = tidy_books %>% inner_join(get_sentiments("bing"), by = "word") %>% count(book, index = linenumber %/% 80, sentiment) %>% spread(sentiment, n, fill = 0) %>% mutate(sentiment = positive - negative)
ggplot(janeaustensentiment) + geom_col(mapping = aes(index, sentiment), show.legend = FALSE)
ggplot(janeaustensentiment) + geom_col(mapping = aes(index, sentiment, fill = book), show.legend = FALSE)
ggplot(janeaustensentiment) + geom_col(mapping = aes(index, sentiment, fill = book), show.legend = FALSE)  %>% facet_wrap(~book, ncol = 2, scales = "free_x")
ggplot(janeaustensentiment) + geom_col(mapping = aes(index, sentiment, fill = book), show.legend = FALSE)  + facet_wrap(~book, ncol = 2, scales = "free_x")
pride_predjudice = tidy_books %>% filter(book == "Pride & Prejudice")
pride_predjudice
afinn = pride_predjudice %>% inner_join(get_sentiments("afinn"), by = "word") %>% group_by(index = linenumber%/%80) %>% summarise(sentiment = sum(score)) %>% mutate(method = "AFINN")
afinn
bing_and_nrc = bind_rows(pride_predjudice %>% inner_join(get_sentiments("bing"), by = "word") %>% mutate(method = "Bing et al."), pride_prejudice %>% inner_join(get_sentiments("nrc") %>% filter(sentiment %in% c("positive", "negative")),  by = "word") %>% mutate(method = "NRC")) %>% count(method, index = linenumber %/%80, sentiment) %>% spread(sentiment, n, fill = 0) %>% mutate(sentiment = positive - negative)
bing_and_nrc = bind_rows(pride_predjudice %>% inner_join(get_sentiments("bing"), by = "word") %>% mutate(method = "Bing et al."), pride_predjudice %>% inner_join(get_sentiments("nrc") %>% filter(sentiment %in% c("positive", "negative")),  by = "word") %>% mutate(method = "NRC")) %>% count(method, index = linenumber %/%80, sentiment) %>% spread(sentiment, n, fill = 0) %>% mutate(sentiment = positive - negative)
pride_prejudice = pride_predjudice
rm(pride_predjudice)
get_sentiments("bing")
get_sentiments("nrc")
get_sentiments("nrc")$sentiment
unique(get_sentiments("nrc")$sentiment)
afinn
bing_and_nrc
unique(bing_and_nrc$method)
bind_rows(afinn, bing_and_nrc) %>% ggplot() %>% geom_col(aes(index, sentiment, fill = method))
ggplot(bind_rows(afinn, bing_and_nrc)) %>% geom_col(aes(index, sentiment, fill = method))
ggplot(bind_rows(afinn, bing_and_nrc)) + geom_col(aes(index, sentiment, fill = method))
ggplot(bind_rows(afinn, bing_and_nrc)) + geom_col(aes(index, sentiment, fill = method), show.legend = FALSE) + facet_wrap(~method, ncol = 1, scales = "free_y")
ggplot(bind_rows(afinn, bing_and_nrc)) + geom_col(aes(index, sentiment, fill = method), show.legend = FALSE) + facet_wrap(~method, ncol = 1)
ggplot(bind_rows(afinn, bing_and_nrc)) + geom_col(aes(index, sentiment, fill = method), show.legend = FALSE) + facet_wrap(~method, ncol = 1, scales = "free_y")
ggplot(bind_rows(afinn, bing_and_nrc)) + geom_col(aes(index, sentiment, fill = method), show.legend = FALSE) + facet_wrap(~method, scales = "free_y")
ggplot(bind_rows(afinn, bing_and_nrc)) + geom_col(aes(index, sentiment, fill = method), show.legend = FALSE) + facet_wrap(~method, nrows = 3, scales = "free_y")
ggplot(bind_rows(afinn, bing_and_nrc)) + geom_col(aes(index, sentiment, fill = method), show.legend = FALSE) + facet_wrap(~method, nrow = 3, scales = "free_y")
get_sentimens("bing")
get_sentiments("bing")
bing_word_counts = tidy_books $>$ inner_join(get_sentiments("bing")) %>% count(word, sentiment, sort = TRUE) %>% ungroup()
bing_word_counts = tidy_books %>% inner_join(get_sentiments("bing")) %>% count(word, sentiment, sort = TRUE) %>% ungroup()
bing_word_counts
bing_word_counts %>% filter(word == "miss")
bing_word_counts %>% filter(word == "happy")
bing_word_counts %>% filter(word == "love")
bing_word_counts
library(wordcloud)
tidy_books %>% anti_join(stop_words) %>% count(word)
tidy_books %>% anti_join(stop_words) %>% count(word)  %>% with(wordcloud(word, n, max.words = 1000))
tidy_books %>% anti_join(stop_words) %>% count(word)  %>% with(wordcloud(word, n, max.words = 100))
library(tidyverse), library(janeaustenr), library(tidytext)
library(tidyverse)
library(tidytext)
library(janeaustenr)
prideprejudice = austen_books() %>% filter(book == "Pride & Prejudice")
prideprejudice
prideprejudice %>% unnest_tokens(sentence, text, token = "sentence")
prideprejudice %>% unnest_tokens(sentence, text, token = "sentences")
prideprejudice %>% unnest_tokens(sentence, text, token = "sentences")$sentence[2]
data_frame(text = prideprejudice) %>% unnest_tokens(sentence, text, token = "sentences")
austen_books()
tidy_books = austen_books() %>% group_by(book) %>% mutate(linenumber = cumsum(str_detect(text, regex("^chapter [\\divxlc]", ignore_case = TRUE)))) %>% ungroup() %>% unnest_tokens(word, text)
library(stringr)
tidy_books = austen_books() %>% group_by(book) %>% mutate(linenumber = cumsum(str_detect(text, regex("^chapter [\\divxlc]", ignore_case = TRUE)))) %>% ungroup() %>% unnest_tokens(word, text)
tidy_books
rm(tidy_books)
tidy_books = austen_books() %>% group_by(book) %>% mutate(linenumber = row_number(), chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]", ignore_case = TRUE)))) %>% ungroup() %>% unnest_tokens(word, text)
tidy_books
tidy_books = select(tidy_books, word, everything())
tidy_books
prideprejudice = tidy_books %>% filter(book = "Pride & Prejudice")
prideprejudice = tidy_books %>% filter(book == "Pride & Prejudice")
prideprejudice
austen_books()
austen_books()$text
prideprejudice
date_frame(text = prideprejudice)
data_frame(text = prideprejudice)
prideprejudice
pride_prejudice = prideprejudice
rm(prideprejudice)
pride_prejudice
prideprejudice
pride_prejudice
class(prideprejudice)
PandP_sentences = data_frame(text = prideprejudice) %>% unnest_tokens(sentence, text, token = "sentences")
PandP_sentences
PandP_sentences$sentence[2]
austen_chapters = austen_books() %>% group_by(book) %>% unnest_tokens(chapter, text, token = "regex", pattern = "Chapter|CHAPTER [\\dIVXLC]") %>% ungroup()
austen_chapters
austen_chapters %>% group_by(book) %>% summarise(chapters = n())
austen_chapters
austen_chapters$chapter
austen_chapters$chapter[0]
austen_chapters$chapter[1]
austen_chapters$chapter[2]
austen_chapters$chapter[5]
bingnegative = get_sentiments("bing") %>% filter(sentiment == "negative")
tidy_books %>% group_by(book, chapter) %>% summarise(n())
wordcounts = tidy_books %>% group_by(book, chapter) %>% summarise(n())
?semi_join
tidy_books %>% semi_join(bingnegative) %>% group_by(book, chapter) %>% summarise(sadwords = n()) %>% inner_join(wordcounts, by = c("book", "chapters")) %>% mutate(ratio = sadwords/wordcounts)
tidy_books %>% semi_join(bingnegative) %>% group_by(book, chapter) %>% summarise(sadwords = n()) %>% inner_join(wordcounts, by = c("book", "chapter")) %>% mutate(ratio = sadwords/wordcounts)
tidy_books %>% semi_join(bingnegative) %>% group_by(book, chapter) %>% summarise(sadwords = n()) %>% left_join(wordcounts, by = c("book", "chapter")) %>% mutate(ratio = sadwords/wordcounts)
tidy_books %>% semi_join(bingnegative) %>% group_by(book, chapter) %>% summarise(negativewords = n()) %>% left_join(wordcounts, by = c("book", "chapter")) %>% mutate(ratio = sadwords/wordcounts)
tidy_books %>% semi_join(bingnegative) %>% group_by(book, chapter) %>% summarise(negativewords = n()) %>% left_join(wordcounts, by = c("book", "chapter")) %>% mutate(ratio = negativewords/wordcounts)
tidy_books %>% semi_join(bingnegative) %>% group_by(book, chapter) %>% summarise(negativewords = n()) %>% left_join(wordcounts, by = c("book", "chapter")) %>% mutate(ratio = negativewords/words)
wordcounts
?rename
rename(wordcounts, "n()", words)
rename(wordcounts, "n()", "words")
rename(wordcounts, words = n())
rename(wordcounts, words = "n()")
tidy_books %>% semi_join(bingnegative) %>% group_by(book, chapter) %>% summarise(negativewords = n()) %>% left_join(wordcounts, by = c("book", "chapter")) %>% mutate(ratio = negativewords/words)
colnames(wordcounts)
wordcounts = rename(wordcounts, words = "n()")
tidy_books %>% semi_join(bingnegative) %>% group_by(book, chapter) %>% summarise(negativewords = n()) %>% left_join(wordcounts, by = c("book", "chapter")) %>% mutate(ratio = negativewords/words)
tidy_books %>% semi_join(bingnegative) %>% group_by(book, chapter) %>% summarise(negativewords = n()) %>% left_join(wordcounts, by = c("book", "chapter")) %>% mutate(ratio = negativewords/words) %>% filter(chapter != 0) %>% top_n(1) %>% ungroup()
proportion_sad = tidy_books %>% semi_join(bingnegative) %>% group_by(book, chapter) %>% summarise(negativewords = n()) %>% left_join(wordcounts, by = c("book", "chapter")) %>% mutate(ratio = negativewords/words) %>% filter(chapter != 0) %>% top_n(1) %>% ungroup()
proportion_sad %>% sort("ratio")
?sort
setwd("C:/Users/Aditya Tyagi/Desktop/Aditya Tyagi (Original)/UC Berkeley Work (3rd Year)/Fall Semester/IEOR142 - Machine Learning & Data Analytics/Course Project/Web Scraping")
base_news = read.csv("base_news.csv")
rm(base_news)
base_news = read.csv("base_news.csv", stringsAsFactors = TRUE)
View(base_news)
fox_news = read.csv("fox_articles.csv", stringsAsFactors = TRUE)
cnn_news = read.csv("cnn_articles.csv", stringsAsFactors = TRUE)
nyt_news1 = read.csv("NYT_articles (2015-2016).csv", stringsAsFactors = TRUE)
nyt_news2 = read.csv("NYT_articles (2016-2017).csv", stringsAsFactors = TRUE)
View(cnn_news)
View(cnn_news)
View(fox_news)
View(fox_news)
View(nyt_news1)
View(nyt_news2)
fox_news = fox_news %>% select(-X)
library(tidyverse)
fox_news = fox_news %>% select(-X)
View(fox_news)
component1 = bind_rows(base_news, cnn_news, fox_news, nyt_news1, nyt_news2)
View(component1)
6252 + 95 + 79 + 303 + 825
table(component1$site_url)
table(component1$type)
component1 = component1 %>% filter(type != c(fake, state))
component1 = component1 %>% filter(type != c("fake", "state"))
table(component1$type)
component1 %>% filter(type == "fake" || type == "state")
component1 %>% filter(type == "fake")
component1 %>% filter(type == "state")
component1 %>% filter(type == "state" | type == "fake")
component1  = component1 %>% filter(!(type == "state" | type == "fake"))
table(component1$type)
alexa = read.csv("alexa_webstats.csv", stringsAsFactors = TRUE)
socialmedia = read.csv("socialmedia_data.csv", stringsAsFactors = TRUE)
View(alexa)
View(component1)
alexa = alexa %>% select(-top4_country, -top5_country, -X, -X.1, -X.2, -X.3, -X.4, -X.5)
View(alexa)
rm(alexa)
alexa = read.csv("alexa_webstats.csv", stringsAsFactors = TRUE)
View(alexa)
alexa = alexa %>% select(-X, -X.1, -X.2, -top4_country, -top5_country)
View(alexa)
alexa = alexa %>% select(-website_country)
View(alexa)
View(socialmedia)
data = component1 %>% left_join(alexa, by = site_url) %>% left_join(socialmedia, by = site_url)
data = component1 %>% left_join(alexa, by = "site_url") %>% left_join(socialmedia, by = "site_url")
View(data)
data = data %>% select(everything(), type)
View(data)
test = data %>% select(type, everything())
View(test)
save.image("C:/Users/Aditya Tyagi/Desktop/Aditya Tyagi (Original)/UC Berkeley Work (3rd Year)/Fall Semester/IEOR142 - Machine Learning & Data Analytics/Course Project/data_prep.RData")
data = data %>% select(site_url, author, headline, language, country, global_rank, US_rank, top1_country, top2_country, top3_country, bounce_rate, dailypageviews_per_visitor, daily_time_on_site, percentage_search_visits, num_sites_linking_in, gender, educational_level, browsing_location, stumble_upon, pinterest, linkedin, fb_total, fb_comments, fb_reactions, fb_shares, type)
data = data %>% select(site_url, author, headline, language, country, global_rank, US_rank, top1_country, top2_country, top3_country, bounce_rate, daily_pageviews_per_visitor, daily_time_on_site, percentage_search_visits, num_sites_linking_in, gender, educational_level, browsing_location, stumble_upon, pinterest, linkedin, fb_total, fb_comments, fb_reactions, fb_shares, type)
View(data)
table(data$type)
count(data$type)
sum(data$type)
5398/7546
1302/7546
?sample
reduced_data = bind_rows(filter(data, type != "bs"), sample(data %>% filter(type == "bs"), 1300)
)
reduced_data = bind_rows(filter(data, type != "bs"), sample_n(data %>% filter(type == "bs"), 1300)
)
290 + 1300 + 260 + 199 + 97 + 1302
table(reduced_data$type
)
1300/3448
reduced_data %>% ggplot() + geom_histogram(aes(x = reduced_data$type))
reduced_data %>% ggplot() + geom_bar(aes(x = reduced_data$type))
reduced_data %>% ggplot() + geom_bar(aes(x = reduced_data$type)) + xlab("Type")
reduced_data %>% ggplot() + geom_bar(aes(x = reduced_data$type), color = "yellow") + xlab("Type")
reduced_data %>% ggplot() + geom_bar(aes(x = reduced_data$type), color = "blue") + xlab("Type")
reduced_data %>% ggplot(color = "green") + geom_bar(aes(x = reduced_data$type)) + xlab("Type")
savehistory("C:/Users/Aditya Tyagi/Desktop/Aditya Tyagi (Original)/UC Berkeley Work (3rd Year)/Fall Semester/IEOR142 - Machine Learning & Data Analytics/Course Project/data_prep.RData")
save.image("C:/Users/Aditya Tyagi/Desktop/Aditya Tyagi (Original)/UC Berkeley Work (3rd Year)/Fall Semester/IEOR142 - Machine Learning & Data Analytics/Course Project/data_prep.RData")
